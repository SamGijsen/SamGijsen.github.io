---
# title: Dr. Sam Gijsen
# feature_text: |
#   Machine Learning for Clinical Neuroimaging
#   Postdoctoral Researcher
# feature_image: "https://picsum.photos/1300/400?image=989"
---

<div style="display: flex; align-items: center; gap: 20px; margin-bottom: 1em;">
  <div>
    <h1 style="margin-bottom: 0.2em;">Dr. Sam Gijsen</h1>
    <p><strong>Postdoctoral Researcher</strong> 
    <br>Machine Learning in Clinical Neuroimaging<br>
    <ul style="margin-top: 0.3em;">
      <li><a href="https://psychiatrie-psychotherapie.charite.de/en/research/translation_and_neurotechnology/machine_learning">Charité - Universitätsmedizin Berlin</a></li>
      <li><a href="https://hertie.ai/machine-learning">Hertie Institute for AI in Brain Health</a></li>
    </ul></p>
  </div>
  <img src="/assets/profile_pic.jpg" alt="Dr. Sam Gijsen" style="width: 200px; height: 200px; border-radius: 50%; object-fit: cover; margin-left: 2em;">
</div>

{% include button.html text="GitHub" icon="github" link="https://github.com/samgijsen" color="#0366d6" %} {% include button.html icon="linkedin" text="LinkedIn" link="https://linkedin.com/in/samgijsen" %} {% include button.html icon="scholar" text="Google Scholar" link="https://scholar.google.com/citations?hl=en&user=bSYq9qoAAAAJ" color="#4285F3" %}

## Selected Work
<hr style="margin: 0.5em 0;">

<div class="title-compact">
  EEG-Language Pretraining for Pathology Detection
  <span>Sam Gijsen, Kerstin Ritter</span>
</div>
<div style="display: flex; gap: 20px; margin-bottom: 2em;">
  <img src="/assets/papers/ELM.png" alt="Project 2" style="width: 350px; object-fit: cover;">
  <div>
    <p>First-of-its-kind EEG-language model for downstream clinical tasks. We show that multimodal models integrating natural language learn more useful representations of neural data.</p>
    <p>
      <a href="https://arxiv.org/abs/2409.07480">arXiv</a> •
      <a >Code to come</a>
    </p>
  </div>
</div>

<hr style="margin: 2.5em 0;">

<div class="title-compact">
  Neural surprise in somatosensory Bayesian learning
  <span>Sam Gijsen, Miro Grundei, Robert T. Lange, Dirk Ostwald, Felix Blankenburg</span>
</div>
<div style="display: flex; gap: 20px; margin-bottom: 2em;">
  <img src="/assets/papers/neural_surprise.png" alt="Project 2" style="width: 400px; object-fit: cover;">
  <div>
    <p>Computational modeling of neural signals using information-theoretic measures shows perceptual learning can be described as a process of probabilistic inference.</p>
    <p>
      <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008068">PLOS Computational Biology</a> • 
      <a href="https://github.com/SamGijsen/SurpriseInSomesthesis">Code</a> 
    </p>
  </div>
</div>

<hr style="margin: 0.5em 0;">

<div class="title-compact">
  Active inference and the two-step task
  <span>Sam Gijsen, Miro Grundei, Felix Blankenburg</span>
</div>
<div style="display: flex; gap: 20px; margin-bottom: 2em;">
  <img src="/assets/papers/twostep.png" alt="Project 2" style="width: 300px; object-fit: cover;">
  <div>
    <p>Compared to reinforcement learning, active inference models can better describe human sequential decision-making using probablistic surprise minimization.</p>
    <p>
      <a href="https://www.nature.com/articles/s41598-022-21766-4">Scientific Reports</a> • 
      <a href="https://github.com/SamGijsen/AI2step">Code</a> 
    </p>
  </div>
</div>

<hr style="margin: 0.5em 0;">

## Latest Blog post

<!-- <div class="title-compact">
  World Diffusion
</div> -->

<div style="display: flex; gap: 20px; margin-bottom: 2em;">
  <img src="/assets/HillsbradDiffusion/morph_15fps.gif" alt="Project 2" style="width: 256px; object-fit: cover;">
  <div>
    <p><strong>Hillsbrad Diffusion: A World Diffusion Model Criminally Undertrained</strong><br> A qualitative look at a world diffusion model undertrained on two hours of sparse exploration of a large map.</p>
    <p>
      <a href="https://samgijsen.github.io/blog/2025/01/27/HillsbradDiffusion">Blog post</a> •
      <!-- <a href="https://github.com/SamGijsen/HillsbradDiffusion">Code</a> -->
    </p>
  </div>
</div>